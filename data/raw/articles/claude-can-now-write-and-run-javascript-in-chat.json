{
  "title": "Claude can now write and run JavaScript in chat",
  "url": "https://www.deeplearning.ai/the-batch/claude-can-now-write-and-run-javascript-in-chat/",
  "text": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\nAllegro, an open-source video generation model from Rhymes AI\nMeta’s new quantized versions of Llama 3.2 1B and 3B\nSynthID text, a new text watermarking tool\nMeta’s Lingua and Self-Taught Evaluator, two model-training tools\nBut first:\nAnthropic boosts Claude with built-in JavaScript execution\nAnthropic added a new analysis tool to Claude that allows the model to write and run JavaScript code within conversations, enabling it to process data and produce real-time insights. This feature functions like a built-in code sandbox, allowing Claude to perform complex calculations, analyze data, and refine ideas before presenting results. The analysis tool builds on Claude Sonnet 3.5’s upgraded coding abilities, offering more accurate and verifiable answers for tasks ranging from marketing analysis to financial reporting. ( Anthropic )\nCohere’s Embed 3 brings multimodal capabilities to AI search\nCohere upgraded its Embed 3 model to process both text and images, enabling more advanced AI-powered search across industries. The embedding model can retrieve relevant graphs, product images, and design files based on text descriptions, outperforming competitors in accuracy and mixed-media searches. Embed 3’s unified approach to text and images simplifies implementation for businesses, potentially enhancing search experiences in e-commerce, data analysis, and other fields. ( Cohere )\nAllegro, a new open-source video generation model\nRhymes AI released Allegro, a model that generates 6-second, 720p video clips from text prompts, under an Apache 2.0 license. Allegro uses large-scale video data processing, video compression into visual tokens, and a scaled-up video diffusion transformer to create high-quality short videos from text descriptions. Allegro’s open-source release aims to spur innovation in AI-generated video by allowing researchers and developers to build upon and improve the technology. ( Rhymes AI )\nMeta shrinks Llama models for faster on-device AI\nMeta released quantized versions of its Llama 3.2 1B and 3B language models, optimized for mobile devices. The new model versions achieve twice to four times the speed of the non-quantized models, a 56 percent reduction in size, and a 41 percent reduction in memory usage compared to the original versions, while maintaining high quality and safety. These mobile versions of Llama 3.2 allow developers to build AI experiences that run entirely on-device, offering improved speed and privacy for users. ( Meta )\nNew Google watermarking tool helps identify AI-written text\nGoogle DeepMind and Hugging Face released SynthID Text, a technology that allows developers to watermark AI-generated text and detect those watermarks using a classifier. The system uses a pseudo-random function to augment the text generation process, making the watermark imperceptible to humans but detectable by trained models. This provides developers a tool to address issues of content attribution and misinformation in AI-generated text. ( Hugging Face and Nature )\nMeta releases two new tools for AI model training\nMeta presented Lingua, a lightweight codebase for training large language models, and Self-Taught Evaluator, a method for generating synthetic preference data to train reward models. Lingua aims to simplify the process of conducting language model experiments, while Self-Taught Evaluator creates contrasting model outputs and uses an LLM to judge them, eliminating the need for human annotations. The Self-Taught Evaluator model outperformed larger models like GPT-4 and Gemini-Pro on RewardBench, demonstrating the potential of synthetic data in AI evaluation and training. ( Meta )\nStill want to know more about what matters in AI right now?\nRead last week’s issue of The Batch for in-depth analysis of news and research.\nLast week, Andrew Ng emphasized the importance of speedy execution with Generative AI and the need to quickly gather user feedback to iterate on products responsibly.\n“A better mantra is ‘move fast and be responsible.’ There are many ways to prototype and test quickly without shipping a product that can cause significant harm.”\nRead Andrew’s full letter here .\nOther top AI news and research stories we covered in depth: Major AI companies plan to meet growing demand with nuclear energy ; the once-strong partnership between Microsoft and OpenAI faces challenges as both companies seek greater independence; Mistral AI launches two models that set new standards for small language models, making them suitable for edge devices; and researchers cut training costs for video generators , resulting in a competitive open-source text-to-video model with training code to be released.\nSubscribe to Data Points\n\n\n",
  "image_filename": "claude-can-now-write-and-run-javascript-in-chat.jpg"
}
{
  "title": "Doing Business with Chatbots",
  "url": "https://www.deeplearning.ai/the-batch/doing-business-with-chatbots/",
  "text": "Dear friends,\nThere are many great applications to be built on top of large language models, and the overhead of doing so may be lower than you think. Sometimes, I’ve spent all day on a weekend developing ideas only to find that I've spent less than $0.50.\nGiven the low cost of keeping me busy all day, It might not surprise you to find that the cost of scaling up a business based on a large language model (LLM) can be quite inexpensive. As a back-of-the-envelope calculation, let’s say:\nIt costs $0.002 per 1,000 tokens, the current price of OpenAI's popular gpt-3.5-turbo conversational model. Pricing can be up to 5x lower or 30x higher depending on the model's quality, but this one is popular among developers, so let's go with it.\nA token corresponds to 0.75 words.\nA user can read 250 words per minute.\nLength of prompts and generated responses is roughly the same.\nThen it costs around $0.08 to generate enough text to keep someone busy for an hour.\nHere are some ways to think about this when it comes to automating or assisting a person’s work task:\nFor most tasks that we might hire someone to do, the cost is significantly more than $0.08 per hour. For example, minimum wage in some places in the US is $15 per hour, and Amazon Mechanical Turk workers might work for around $5 per hour. So the cost of using an LLM to automate of most human tasks is very inexpensive.\nIf you’re generating text for a person to read, the cost of the time spent reading is significantly greater than the cost of generating the text.\nOn the flip side:\nUp to an order of magnitude, social media companies might make around $0.10 per hour that a user spends on their sites. So if we’re generating personalized text for one person, the financial case is iffy. (I don’t think this is necessarily a bad thing. Society doesn’t need people to spend even more time on social media!)\nOn the other hand, if we’re generating content to be read by a large audience, such as a news article, then the cost is amortized across the audience, and it is quite inexpensive again.\nPlease don’t use my back-of-the-envelope calculation for any significant business decisions, and do carry out your own calculations with careful assumptions specific to your project. But if you haven’t stepped through such a calculation before, the takeaway is that LLMs are actually quite inexpensive to use.\nGranted, some models (like one version of GPT-4, at 15-30x the cost used in the calculation, leading to a cost of $1.80 instead of $0.08) are much more expensive. If your application requires a more capable model, then the calculation does change. But I’m optimistic that prices will come down over time, and these are all wonderful tools to have in your toolbox.\nKeep learning!\nAndrew\nP.S. I’ve noticed that most LLM providers don’t have transparent pricing. If you work at an LLM provider, I hope you’ll consider urging your company to list prices on its website.\n\n\n",
  "image_filename": "doing-business-with-chatbots.gif"
}
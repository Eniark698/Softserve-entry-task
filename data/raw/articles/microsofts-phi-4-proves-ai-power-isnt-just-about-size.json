{
  "title": "Microsoft’s Phi-4 proves AI power isn’t just about size",
  "url": "https://www.deeplearning.ai/the-batch/microsofts-phi-4-proves-ai-power-isnt-just-about-size/",
  "text": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\nNotebookLM gets a plus-sized update\nMeta’s Motivo model marks a return to the metaverse\nNew synthetic data generator makes training easier\nNeurIPS 2024’s sabotage controversy\nBut first:\nMicrosoft’s Phi-4 (14B) outperforms Llama 3.3 (70B) at math and code\nMicrosoft introduced Phi-4, a 14 billion parameter language model that demonstrates exceptional reasoning abilities, particularly in mathematics and coding. Despite its relatively small size, the model outperforms larger competitors, including GPT-4 and Llama 3.3 70B, on graduate-level STEM questions and math competition problems. Phi-4’s success stems from innovative approaches to synthetic data generation, optimized training curricula, and advanced post-training techniques. The model’s performance shows that carefully curated data can lead smaller, more efficient AI models to rival or surpass larger language models in specialized tasks. ( Microsoft and arXiv )\nChatGPT gets organizational and collaborative boost with Projects and Canvas\nOpenAI introduced two significant updates to ChatGPT: Projects and Canvas. Projects allows users to organize conversations, files, and data within themed spaces, streamlining workflows for tasks like website development or screenplay writing. Canvas, a side-by-side interface, enhances collaborative writing and coding with features like integrated Python execution, custom GPTs, and advanced editing tools. Both additions address user frustrations with conversation management and workflow organization, potentially transforming how AI developers and frequent ChatGPT users interact with the platform for complex tasks. These features represent OpenAI’s efforts to make ChatGPT a more powerful and versatile tool for creative and technical collaborations. ( OpenAI )\nGoogle revamps NotebookLM with new features and paid subscription version\nGoogle rolled out significant updates to NotebookLM, its AI-powered research assistant, including a redesigned interface, interactive Audio Overviews, and a premium subscription called NotebookLM Plus. The new interface organizes content into three panels for sources, chat, and content generation, while the interactive Audio Overviews allow users to engage directly with AI hosts using voice commands. NotebookLM Plus offers higher usage limits, customization options, and enterprise-grade features for organizations, signaling Google’s push to monetize and expand its AI productivity offerings. ( Google )\nMeta unveils humanoid AI agent for complex task performance\nMeta released Meta Motivo, a behavioral foundation model that controls a virtual humanoid agent to perform complex tasks without additional training. The model uses a novel algorithm that leverages unlabeled motion data to ground unsupervised reinforcement learning towards human-like behaviors while maintaining zero-shot inference capabilities. Meta Motivo’s ability to solve a wide range of whole-body control tasks and its robustness to environmental changes could lead to more lifelike non-player characters and new immersive experiences in virtual environments. ( Meta AI )\nSynthetic data generator simplifies AI dataset creation\nDevelopers at Argilla introduced a no-code tool that allows users to create custom synthetic datasets using large language models. The application supports text classification and chat datasets, generating samples at a rate of 50 and 20 per minute respectively using the free Hugging Face API. This tool streamlines the process of creating training data for AI models, potentially accelerating development cycles for AI researchers and companies building language models. ( Hugging Face )\nTop AI conference faces ethical dilemma over best paper award\nKeyu Tian, lead author of one of two best papers at NeurIPS 2024, allegedly sabotaged colleagues’ research projects during an internship at ByteDance. A protest letter posted on GitHub details Tian’s misconduct, including modifying code, disrupting experiments, and illegally accessing company resources to advance his own work. (ByteDance terminated Tian’s internship when his behavior was discovered this fall.) This situation raises questions about academic integrity and the values promoted by recognizing valuable research when it’s potentially tainted by unethical behavior. ( GitHub )\nStill want to know more about what matters in AI right now?\nRead last week’s issue of The Batch for in-depth analysis of news and research.\nLast week, Andrew Ng shared emerging best practices for AI Product Management, including starting with concrete examples, assessing technical feasibility through prompting, and managers rapidly building prototypes without involving engineers.\n“AI is enabling a lot of new applications to be built, creating massive growth in demand for AI product managers who know how to scope out and help drive progress in building these products. AI product management existed before the rise of generative AI, but the increasing ease of building applications is creating greater demand.”\nRead Andrew’s full letter here .\nOther top AI news and research stories we covered in depth: Amazon unveiled Nova models for text, image, and video, offering competitive performance at competitive prices ; OpenAI introduced an updated o1 and o1 pro mode for advanced reasoning , available in a new plan called GPTPro, priced at $200/month; Google launched Genie 2 , bringing interactive 3D worlds to life; and researchers at Lamini proposed a memory method designed to reduce hallucinations in large language models, enhancing factual accuracy.\nSubscribe to Data Points\n\n\n",
  "image_filename": "microsofts-phi-4-proves-ai-power-isnt-just-about-size.jpg"
}
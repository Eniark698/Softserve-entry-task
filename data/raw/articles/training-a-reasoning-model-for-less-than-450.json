{
  "title": "Training a reasoning model for less than $450",
  "url": "https://www.deeplearning.ai/the-batch/training-a-reasoning-model-for-less-than-450/",
  "text": "Twice a week, Data Points brings you the latest AI news, tools, models, and research in brief. In today’s edition, you’ll find:\nMoondream’s lightweight vision model adds gaze detection\nFine-tuning Flux Pro’s generative model with just a few images\nCopilot Chat brings simple agents to Microsoft 365\nGoogle adds Gemini to all its Workspace plans\nBut first:\nBerkeley students build affordable AI model rivaling top performers\nResearchers at UC-Berkeley developed Sky-T1-32B-Preview, an open-source AI model (including open code and datasets) based on Qwen2.5-32B-Instruct. Sky-T1-32B-Preview matches the performance of leading proprietary models in reasoning and coding tasks. Sky-T1-32B-Preview achieved impressive results on various benchmarks, including 56.8 percent accuracy on GPQA-Diamond and 17.9 percent on LiveCodeBench-Hard, positioning it competitively against established models like QwQ and o1-preview. The model was trained for less than $450, showing that high-level AI capabilities can be replicated affordably. Low-cost, high-performing projects like these could democratize access to advanced AI technologies, enabling broader participation from academic and open-source communities in cutting-edge AI research and development. ( Novasky )\nChatGPT gains scheduling abilities with new Tasks feature\nOpenAI introduced Tasks, a beta feature for ChatGPT that allows paid subscribers to schedule future actions and reminders. Users can set one-time or recurring tasks, manage them through a dedicated interface, and receive notifications upon completion, with a limit of 10 active tasks running simultaneously. Tasks signals OpenAI’s expansion of ChatGPT’s capabilities beyond real-time conversations into the realm of semi-autonomous digital assistants, potentially paving the way for more advanced “agentic” AI functionalities in the future. ( OpenAI )\nMoondream expands AI vision capabilities with compact new model\nMoondream released version 1.9B with new features including structured output support, gaze detection, and improved OCR capabilities. The update also focused on industry vision language benchmarks for the first time, with Moondream performing competitively against other small vision language models on tests like ChartQA, RealWorldQA, and POPE while maintaining its compact 1.9 billion parameter size. In particular, Moondream touts its ability to run with just over 4 GB of RAM, less than comparably sized competitors like Qwen2-VL 2B, InternVL2 2B, and PaliGemma 3B, making it less expensive to run or test when using similar hardware. ( Moondream )\nBlack Forest Labs launches new API for customized image generation\nBlack Forest Labs introduced a new FLUX Pro Finetuning API, allowing users to fine-tune the company’s text-to-image model with as few as one to five example images. Fine-tuning via the API enables users to maintain the base model’s versatility while allowing them to easily reimagine user-provided content through text prompts. This capability offers AI developers new tools for creating brand-consistent visuals and personalized content for various applications, from marketing to storytelling. ( Black Forest Labs )\nMicrosoft expands AI offerings with new Copilot Chat service\nMicrosoft introduced Copilot Chat, a pay-as-you-go service that adds AI agents to its free chat experience for Microsoft 365 commercial customers. The new offering includes web-grounded chat powered by GPT-4o, easily accessible agents, and IT controls for enterprise data protection and agent management. Agents in Copilot Chat allow employees to automate repetitive tasks and business processes using natural language, with IT administrators able to build organization-wide agents and manage their deployment through Microsoft Copilot Studio. This development provides AI practitioners with a new platform to create and deploy custom AI agents at scale, potentially accelerating the adoption of LLM-based automation in enterprise. ( Microsoft )\nGoogle makes AI standard in Workspace, aiming for wider business adoption\nNot to be outdone, Google announced its Workspace Business and Enterprise plans will include the company’s latest generative AI capabilities without requiring additional add-ons. The move integrates AI tools like Gemini into everyday applications such as Gmail, Docs, and Meet, aiming to boost performance, productivity, and creativity for businesses of all sizes. This updated pricing model for Workspace reduces costs for customers who already use Gemini and provides broader access to Google’s most advanced AI features. ( Google )\nStill want to know more about what matters in AI right now?\nRead this week’s issue of The Batch for in-depth analysis of news and research.\nThis week, Andrew Ng shared his thoughts on the growing demand for AI product management and how AI advancements are transforming roles within software development teams.\n“Given a clear specification for what to build, AI is making the building itself much faster and cheaper. This will significantly increase demand for people who can come up with clear specs for valuable things to build.”\nRead Andrew’s full letter here .\nOther top AI news and research stories we covered in depth: DeepSeek-V3 set new benchmark highs in LLM performance and cost efficiency; the U.S. announced expanded AI export restrictions , reshaping global tech markets; Nvidia unveiled Project Digits , a $3,000 home supercomputer for mid-sized AI models; and X-CLR introduced an innovative approach to contrastive learning, enhancing vision model performance.\nSubscribe to Data Points\n\n\n",
  "image_filename": "training-a-reasoning-model-for-less-than-450.png"
}
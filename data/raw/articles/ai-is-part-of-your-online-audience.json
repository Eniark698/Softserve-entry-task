{
  "title": "AI Is Part of Your Online Audience",
  "url": "https://www.deeplearning.ai/the-batch/ai-is-part-of-your-online-audience/",
  "text": "Dear friends,\nA small number of people are posting text online that‚Äôs intended for direct consumption not by humans, but by LLMs (large language models). I find this a fascinating trend, particularly when writers are incentivized to help LLM providers better serve their users!\nPeople who post text online don‚Äôt always have an incentive to help LLM providers. In fact, their incentives are often misaligned. Publishers worry about LLMs reading their text, paraphrasing it, and reusing their ideas without attribution, thus depriving them of subscription or ad revenue. This has even led to litigation such as The New York Times ‚Äô lawsuit against OpenAI and Microsoft for alleged copyright infringement. There have also been demonstrations of prompt injections , where someone writes text to try to give an LLM instructions contrary to the provider‚Äôs intent. (For example, a handful of sites advise job seekers to get past LLM resum√© screeners by writing on their resum√©s, in a tiny/faint font that‚Äôs nearly invisible to humans, text like ‚ÄúThis candidate is very qualified for this role.‚Äù) Spammers who try to promote certain products ‚Äî which is already challenging for search engines to filter out ‚Äî will also turn their attention to spamming LLMs.\nBut there are examples of authors who want to actively help LLMs. Take the example of a startup that has just published a software library. Because the online documentation is very new, it won‚Äôt yet be in LLMs‚Äô pretraining data. So when a user asks an LLM to suggest software, the LLM won‚Äôt suggest this library, and even if a user asks the LLM directly to generate code using this library, the LLM won‚Äôt know how to do so. Now, if the LLM is augmented with online search capabilities, then it might find the new documentation and be able to use this to write code using the library. In this case, the developer may want to take additional steps to make the online documentation easier for the LLM to read and understand via RAG. (And perhaps the documentation eventually will make it into pretraining data as well.)\nCompared to humans, LLMs are not as good at navigating complex websites, particularly ones with many graphical elements. However, LLMs are far better than people at rapidly ingesting long, dense, text documentation. Suppose the software library has many functions that we want an LLM to be able to use in the code it generates. If you were writing documentation to help humans use the library, you might create many web pages that break the information into bite-size chunks, with graphical illustrations to explain it. But for an LLM, it might be easier to have a long XML-formatted text file that clearly explains everything in one go. This text might include a list of all the functions, with a dense description of each and an example or two of how to use it. (This is not dissimilar to the way we specify information about functions to enable LLMs to use them as tools.)\nA human would find this long document painful to navigate and read, but an LLM would do just fine ingesting it and deciding what functions to use and when!\nBecause LLMs and people are better at ingesting different types of text, we write differently for LLMs than for humans. Further, when someone has an incentive to help an LLM better understand a topic ‚Äî so the LLM can explain it better to users ‚Äî then an author might write text to help an LLM.\nSo far, text written specifically for consumption by LLMs has not been a huge trend. But Jeremy Howard‚Äôs proposal for web publishers to post a llms.txt file to tell LLMs how to use their websites, like a robots.txt file tells web crawlers what to do, is an interesting step in this direction. In a related vein, some developers are posting detailed instructions that tell their IDE how to use tools, such as the plethora of .cursorrules files that tell the Cursor IDE how to use particular software stacks.\nI see a parallel with SEO (search engine optimization). The discipline of SEO has been around for decades. Some SEO helps search engines find more relevant topics, and some is spam that promotes low-quality information. But many SEO techniques ‚Äî those that involve writing text for consumption by a search engine, rather than by a human ‚Äî have survived so long in part because search engines process web pages differently than humans, so providing tags or other information that tells them what a web page is about has been helpful.\nThe need to write text separately for LLMs and humans might diminish if LLMs catch up with humans in their ability to understand complex websites. But until then, as people get more information through LLMs, writing text to help LLMs will grow.\nKeep learning!\nAndrew\nP.S. I like LLMs, but I like humans even more. So please keep writing text for humans as well. üòÄ\n\n\n",
  "image_filename": "ai-is-part-of-your-online-audience.jpg"
}
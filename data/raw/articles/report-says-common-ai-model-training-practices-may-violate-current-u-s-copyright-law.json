{
  "title": "Report says common AI model training practices may violate current U.S. copyright law",
  "url": "https://www.deeplearning.ai/the-batch/report-says-common-ai-model-training-practices-may-violate-current-u-s-copyright-law/",
  "text": "In today’s edition, you’ll learn more about:\nMicrosoft joins Google’s Agent2Agent project\nPolice and governments circumvent face-tracking laws\nOpenAI and Microsoft reportedly seek a new deal\nResearchers use RL to train coding models starting with zero data\nBut first:\nU.S. Copyright Office releases AI fair use report amid leadership upheaval\nThe U.S. Copyright Office quietly posted a pre-publication version of its AI and fair use report just one day before Register of Copyrights Shira Perlmutter was dismissed by the Trump administration. The 108-page document addresses how copyright law should apply to using protected works for AI training, often siding with creators over tech platforms. The report concludes that AI training datasets “clearly implicate the right of reproduction” and suggests model weights themselves may constitute copyright infringement when they retain substantial protected expression. It rejects arguments that AI training is merely “non-expressive” or analogous to human learning, while advancing a “market dilution” theory that AI-generated content could harm original creators through volume and stylistic imitation. But the report also notes that many uses of AI may qualify as fair use and that many factors need to be considered to make a judgement on any particular case. The report’s future as official policy remains uncertain following the controversial dismissals of both Perlmutter and Librarian of Congress Dr. Carla Hayden. ( U.S. Copyright Office and Copyright Lately )\nFully open-source vision encoders match or exceed proprietary models\nResearchers at UC-Santa Cruz introduced OpenVision, a fully open-source family of vision encoders that match or surpass proprietary models like OpenAI’s CLIP when used in multimodal AI systems. The authors developed these encoders using public data and transparent training methods, creating models ranging from 5.9 million to 632 million parameters to suit various deployment scenarios. When integrated into multimodal frameworks like LLaVA, OpenVision models demonstrated superior performance on tasks involving text recognition, chart analysis, and visual reasoning compared to closed-source alternatives. The team identified key factors contributing to their success, including an auxiliary text decoder, high-quality synthetic captions, and progressive resolution training that significantly reduced computational costs. All code, training data, and model weights are publicly available, enabling researchers to build more transparent and adaptable multimodal AI systems. ( arXiv and Hugging Face )\nMicrosoft embraces Google’s Agent2Agent protocol\nMicrosoft announced support for the open-source Agent2Agent (A2A) protocol in Azure AI Foundry and Copilot Studio, enabling AI agents to collaborate across different clouds, platforms, and organizations. The A2A protocol will allow structured agent communication with enterprise-grade safeguards including Microsoft Entra, mutual TLS, Azure AI Content Safety, and comprehensive audit logs. Microsoft has joined the A2A working group on GitHub to contribute to the specification and tooling, with public preview in Foundry and Copilot Studio coming soon. ( Microsoft )\nPolice use AI tool to track people where facial recognition is banned\nVeritone’s AI tracking tool called “Track” allows police and federal agencies to identify people using non-facial attributes like body size, gender, clothing, and accessories. The technology is being used by 400 customers including police departments and universities across the U.S., with the Department of Justice, Homeland Security, and Defense Department also employing Veritone’s suite of AI tools. Track was specifically designed to help authorities identify individuals in jurisdictions where facial recognition has been banned or in situations where faces are obscured. The ACLU has criticized the technology as potentially authoritarian, warning it creates unprecedented surveillance capabilities that could be abused, particularly amid increased monitoring of protesters, immigrants, and students. Track’s expansion comes as more jurisdictions restrict facial recognition due to concerns about accuracy and wrongful arrests, with the tool potentially offering a way to circumvent these legal limitations. ( MIT Technology Review )\nOpenAI and Microsoft renegotiate partnership terms ahead of potential IPO\nOpenAI and Microsoft are revising their multibillion-dollar partnership to accommodate OpenAI’s plans for a potential initial public offering while ensuring Microsoft maintains access to cutting-edge AI technology, according to sources cited in a new report in the Financial Times. A key issue in negotiations is how much equity Microsoft will receive in exchange for its $13 billion investment as OpenAI seeks to restructure into a public benefit corporation. Microsoft is reportedly offering to reduce its equity stake in OpenAI’s new for-profit business in exchange for access to technology developed beyond their current contract’s 2030 expiration date. The negotiations are complicated by increasing competitive tensions between the companies, with OpenAI pursuing enterprise customers and seeking partnerships with SoftBank and Oracle to build its own computing infrastructure. OpenAI’s restructuring faces additional challenges, including legal action from co-founder Elon Musk and regulatory scrutiny from authorities in California and Delaware. ( Financial Times )\nAbsolute Zero Reasoner achieves state-of-the-art performance without external data\nResearchers at Tsinghua University, the Beijing Institute, and Pennsylvania State University have developed a new approach to training AI reasoning systems that doesn’t require human-curated data. The Absolute Zero Reasoner (AZR) learns through a self-play process where it proposes coding tasks, solves them, and improves from feedback, using a code executor to validate solutions. In testing, AZR outperformed several models trained on expert-curated examples in coding tasks and showed competitive performance in mathematical reasoning. The system demonstrated effective cross-domain transfer, with improvements scaling better on larger models. This approach could help address the scalability challenges of current methods that rely on human-curated datasets, which become increasingly difficult to produce as AI systems advance. ( arXiv )\nStill want to know more about what matters in AI right now?\nRead last week’s issue of The Batch for in-depth analysis of news and research.\nLast week, Andrew Ng announced that AI Fund had closed $190M for a new venture fund and shared key lessons on how speed drove success in AI startups.\n“Because AI technology is evolving rapidly, a team with a deep technical understanding of what AI can and cannot do, and when to use what tool, will make better decisions. This creates meaningful differentiation and saves wasting time in blind alleys. A good technical understanding, too, gets you speed!”\nRead Andrew’s full letter here .\nOther top AI news and research stories we covered in depth: Alibaba released the Qwen3 family of open-source language models , offering optional reasoning capabilities that rival top models like DeepSeek-R1; OpenAI rolled back its GPT-4o update after users flagged overly flattering, sycophantic behavior; Johnson & Johnson unveiled a revised AI strategy , offering new insights into how big medical companies are using the technology; and researchers demonstrated that fine-tuning a language model with just 1,000 examples can significantly boost its reasoning abilities.\nSubscribe to Data Points\n\n\n",
  "image_filename": "report-says-common-ai-model-training-practices-may-violate-current-u-s-copyright-law.png"
}
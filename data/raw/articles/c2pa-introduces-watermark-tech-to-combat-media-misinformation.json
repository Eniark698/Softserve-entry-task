{
  "title": "Standard for Media Watermarks",
  "url": "https://www.deeplearning.ai/the-batch/c2pa-introduces-watermark-tech-to-combat-media-misinformation/",
  "text": "An alliance of major tech and media companies introduced a watermark designed to distinguish real from fake media starting with images.\nWhat’s new: The Coalition for Content Provenance and Authenticity (C2PA) offers an open standard that marks media files with information about their creation and editing. C2PA’s 30 members, including both tech powers (Adobe, Google, Intel, Microsoft, X) and media outlets (BBC, CBC, The New York Times ) will deploy the standard in the coming year, IEEE Spectrum reported .\nHow it works: The C2PA’s Content Credentials specification accommodates a variety of file types, but currently it’s implemented mainly for images.\nWhen a C2PA-compliant image generator or editor produces an image, it invisibly embeds a cryptographic watermark that contains the following metadata: the user or device that initially created the image, when and how it was created, and how it was edited or otherwise transformed. (Actions using non-compliant tools are not recorded.)\nImages can display a small “cr” icon in the corner. Clicking on the icon reveals the metadata.\nAny alteration of the file or any attempt to tamper with it will cause a mismatch between the watermark and its associated metadata.\nSocial media recommenders and image search algorithms can use the metadata to identify, restrict, or promote certain types of media.\nWho’s using it: Image generators from Adobe and Microsoft stamp their outputs with Content Credential watermarks, marking them as synthetic; Microsoft also promotes watermarking by political campaigns to help voters differentiate synthetic from non-generated campaign messages. Camera manufacturers Canon, Leica , and Nikon have built prototype cameras that use Content Credentials to mark the origin of photographs. BBC is using the technology to mark images on its website on a trial basis, and Canada’s CBC plans to deploy it in mid-2024.\nYes, but: It may be difficult to fake Content Credentials, but it’s easy to remove the watermark from images, even from AI-generated ones. Using a Content Credentials-compliant tool like Photoshop, you can disable Content Credentials and save a watermarked image to a different format. This produces an identical image without the watermark.\nBehind the news: The C2PA unites the Content Authenticity Initiative (led by Adobe) and Project Origin (led by media companies). Nonetheless, the field remains fragmented. For instance, Meta (not a C2PA member) has aimed to identify AI-generated media using detection software. However, C2PA argues that detectors aren’t sufficiently effective; the winner of a Meta deepfake-detection challenge identified generated content only 65 percent of the time. Top AI companies committed to developing their own watermarking mechanisms, but they haven’t settled on Content Credentials or another standard.\nWhy it matters: Distinguishing generated text, imagery, and audio from media that accurately depicts real-world events is a key challenge for the generative AI era. The coming year will test that ability as 78 countries gear up elections that will affect roughly half the world’s population. Already, campaigns have used generated imagery in Argentina , New Zealand , South Korea , the United States , and other nations. Google and Meta responded by tightening restrictions on political advertisers’ use of generative AI. The EU’s AI Act will require clear labeling of AI-generated media, and the U.S. Federal Election Commission plans to restrict ads that depict political opponents saying or doing things they did not actually say or do. If Content Credentials proves effective in the coming election season, it may ease the larger problem of identifying generated media in a variety of venues where authenticity is important.\nWe’re thinking: A robust watermark can identify both traditional and AI-generated media for users and algorithms to treat accordingly. It can also potentially settle claims that a doctored image was authentic or that authentic work was doctored. However, we worry that watermarking generated outputs may prove to be a disadvantage in the market , creating a disincentive for makers of software tools to provide it and users to use it. With heavyweight members from both tech and media, C2PA may be able to build sufficient momentum behind the watermarking to make it stick.\n\n\n",
  "image_filename": "c2pa-introduces-watermark-tech-to-combat-media-misinformation.gif"
}
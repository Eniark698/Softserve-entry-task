{
  "title": "Do Large Language Models Threaten Google?",
  "url": "https://www.deeplearning.ai/the-batch/chatgpt-and-other-llm-could-disrupt-googles-business/",
  "text": "Dear friends,\nIn late December, Google reportedly issued a “code red” to raise the alarm internally to the threat of disruption of its business by large language models like OpenAI’s ChatGPT.\nDo large language models (LLMs) endanger Google's search engine business? I think there’s a path for them to transform the way we access information, albeit one that poses technical and business hurdles.\nWhat if, rather than searching the web, we could query an LLM and get an answer? We would receive not a page of web links but a piece of text that answered our query. This appears to work for basic factual questions, but for questions that require complex reasoning or specialized knowledge, today’s LLMs may confidently hallucinate an answer, making the result misleading .\nHere’s one way to think about the problem. ChatGPT’s predecessor GPT-3 has 175 billion parameters. Using 16-bit, floating-point bytes, it would take around 350GB to store its parameters (many reports say 800GB). In comparison, Wikipedia occupies about 150GB (50GB for text, 100GB for images). While the comparison is far from apples to apples, the fact that an LLM has more memory than is needed to store Wikipedia suggests its potential to store knowledge.\nBut even Wikipedia contains a minuscule fraction of the knowledge available on the internet, which by some estimates amounts to 5 billion GB. Thus search, which can point us to pages from all corners of the web, can answer many questions that an LLM with fixed memory can't.\nThat said, I see significant potential in another technology, retrieval augmented generation. Rather than relying on a fixed LLM to deliver the answer to a query, if we first find relevant documents (online or elsewhere) and then use an LLM to process the query and the documents into an answer, this could provide an alternative to current web search. Executing this efficiently and at scale would be complex, but the effect would be akin to having an LLM do a web search and summarize the results. Examples of this approach include Meta's Atlas and DeepMind's RETRO .\nWhile today's search engine giants are well positioned to execute on this technology, their businesses depend on users clicking on ads placed next to search results. If they were to deliver text that answered a query, where would ads fit into the picture? Google would need to solve that problem before it could replace traditional web search with LLMs. Search startups that don’t have as much to lose — or perhaps Microsoft’s Bing, which is the second most-popular search engine by some reckonings — may be more willing to embrace upheavals in the search-engine business model.\nOf course, Google's business has many moats, or defenses. The company's control over the Chrome web browser and Android mobile operating system channels users to its search engine. Having a platform with many advertisers and a sophisticated ad system also enables Google to monetize user attention better than competitors. Thus, it can pay more for search traffic to, say, incentivize makers of web browsers to make it the default search engine.\nIt's fascinating that generative AI is already so powerful that Google declared an emergency. How exciting to live in a time when we can be part of this evolution of AI!\nKeep learning,\nAndrew\n\n\n",
  "image_filename": "chatgpt-and-other-llm-could-disrupt-googles-business.png"
}
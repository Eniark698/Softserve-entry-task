{
  "title": "Toward Explainable AI",
  "url": "https://www.deeplearning.ai/the-batch/toward-explainable-ai/",
  "text": "Machine learning systems are infamous for making predictions that can’t readily be explained. Now Microsoft offers an open source tool kit providing a variety of ways to interrogate model.\nWhat's in the package: InterpretML implements Explainable Boosting Machine, a generative additive model that delivers both high accuracy and high explainability. The package also comes with several methods to generate explanations of model behavior for regression and binary classification models. Developers can compare explanations produced by different methods and check consistency among models.\nWhy it matters: Building models that can explain how they reach their conclusions is critical in life-and-death situations like transportation, healthcare, and law enforcement. And it’s a top priority in high-stakes industries such as finance where decisions may be called into question. Understanding the behavior of intelligent systems is important to:\ndebug models\ndetect bias\nmeet regulatory requirements\ndefend legal challenges\nestablish trust in a system’s output\nWhat’s next: Principal researcher Rich Caruana and his colleagues aim to improve InterpretML’s categorical encoding and add support for multi-class classification and missing values. They’re hopeful the open source community will build on their work to illuminate what goes on inside machine learning's proliferating black boxes.\n\n\n",
  "image_filename": "toward-explainable-ai.png"
}